{
 "metadata": {
  "name": "",
  "signature": "sha256:a8279a66bb8081ce85f0b7ea93a486102222c036d8a1cc67eba6fa86a23cdf79"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Outlier Detection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Preamble\n",
      "\n",
      "- *Sami Niemi (s.niemi@ucl.ac.uk)*\n",
      "- *Data Analysis and Image Processing with Python, UCL/MSSL, November 4-5 2014*\n",
      "- *Notebook available on [github](https://github.com/sniemi/DataAnalysisPythonCourse)*"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "The following example is adaopted from sklearn"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pylab as pl\n",
      "import matplotlib.font_manager\n",
      "from scipy import stats\n",
      "from sklearn import svm\n",
      "from sklearn.covariance import EllipticEnvelope\n",
      "\n",
      "#set the seed to get the same result...\n",
      "np.random.seed(42)\n",
      "\n",
      "#number of points and outlier fraction\n",
      "n_samples = 320\n",
      "outliers_fraction = 0.25\n",
      "\n",
      "#the separation the data cluers may have\n",
      "clusters_separation = [0, 1]\n",
      "\n",
      "# define two outlier detection tools to be compared\n",
      "classifiers = {\"One-Class SVM\": svm.OneClassSVM(nu=0.95 * outliers_fraction + 0.05,\n",
      "                                                kernel=\"rbf\", gamma=0.1),\n",
      "               \"robust covariance estimator\": EllipticEnvelope(contamination=.1)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#x, y grid in which the data live\n",
      "xx, yy = np.meshgrid(np.linspace(-7, 7, 500), np.linspace(-7, 7, 500))\n",
      "\n",
      "#number of in- and outliers\n",
      "n_inliers = int((1. - outliers_fraction) * n_samples)\n",
      "n_outliers = int(outliers_fraction * n_samples)\n",
      "\n",
      "ground_truth = np.ones(n_samples, dtype=int)\n",
      "ground_truth[-n_outliers:] = 0\n",
      "\n",
      "# Fit the problem with varying cluster separation\n",
      "for i, offset in enumerate(clusters_separation):\n",
      "    # Data generation\n",
      "    X1 = 0.3 * np.random.randn(0.5 * n_inliers, 2) - offset\n",
      "    X2 = 0.3 * np.random.randn(0.5 * n_inliers, 2) + offset\n",
      "    X = np.r_[X1, X2]\n",
      "    \n",
      "    # Add outliers\n",
      "    X = np.r_[X, np.random.uniform(low=-6, high=6, size=(n_outliers, 2))]\n",
      "\n",
      "    # Fit the model with the One-Class SVM\n",
      "    pl.figure(figsize=(10, 5))\n",
      "    for i, (clf_name, clf) in enumerate(classifiers.iteritems()):\n",
      "        # fit the data \n",
      "        clf.fit(X)\n",
      "        \n",
      "        #tag outliers\n",
      "        y_pred = clf.decision_function(X).ravel()\n",
      "        threshold = stats.scoreatpercentile(y_pred, 100*outliers_fraction)\n",
      "        \n",
      "        #makr the ones above threshold\n",
      "        y_pred = y_pred > threshold\n",
      "        \n",
      "        #calculate the sum of mistakes\n",
      "        n_errors = (y_pred != ground_truth).sum()\n",
      "        \n",
      "        \n",
      "        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
      "        Z = Z.reshape(xx.shape)\n",
      "        \n",
      "        #plot the levels lines and the points\n",
      "        subplot = pl.subplot(1, 2, i + 1)\n",
      "        subplot.set_title(\"Outlier detection\")\n",
      "        \n",
      "        subplot.contourf(xx, yy, Z, levels=np.linspace(Z.min(), threshold, 7),\n",
      "                         cmap=pl.cm.Blues_r)\n",
      "        a = subplot.contour(xx, yy, Z, levels=[threshold],\n",
      "                            linewidths=2, colors='red')\n",
      "        subplot.contourf(xx, yy, Z, levels=[threshold, Z.max()],\n",
      "                         colors='orange')\n",
      "        \n",
      "        b = subplot.scatter(X[:-n_outliers, 0], X[:-n_outliers, 1], c='white')\n",
      "        c = subplot.scatter(X[-n_outliers:, 0], X[-n_outliers:, 1], c='black')\n",
      "        \n",
      "        subplot.axis('tight')\n",
      "        subplot.legend([a.collections[0], b, c],\n",
      "                       ['learned decision function', 'true inliers', 'true outliers'],\n",
      "                       prop=matplotlib.font_manager.FontProperties(size=11),\n",
      "                       numpoints=1, shadow=True, fancybox=True, scatterpoints=1)\n",
      "        \n",
      "        subplot.set_xlabel(\"%d. %s (errors: %d)\" % (i + 1, clf_name, n_errors))\n",
      "        subplot.set_xlim((-7, 7))\n",
      "        subplot.set_ylim((-7, 7))\n",
      "    pl.subplots_adjust(0.04, 0.1, 0.96, 0.94, 0.1, 0.26)\n",
      "\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}